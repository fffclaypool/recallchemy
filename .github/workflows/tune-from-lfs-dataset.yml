name: Tune From LFS Dataset

on:
  workflow_dispatch:
    inputs:
      scenario_name:
        description: "Scenario to run (primary path)"
        required: true
        type: choice
        default: "ambiguous-hard"
        options:
          - ambiguous-hard
          - example
      dataset_path:
        description: "Optional dataset path override (repository-relative, Git LFS tracked). Empty uses scenario dataset.path"
        required: false
        default: ""
        type: string
      metric:
        description: "Optional metric override (empty uses scenario)"
        required: false
        default: ""
        type: string
      backends:
        description: "Optional backends override: all / hnswlib annoy faiss-ivf (empty uses scenario)"
        required: false
        default: ""
        type: string
      trials:
        description: "Optional trials override (empty uses scenario)"
        required: false
        default: ""
        type: string
      trial_budgets:
        description: "Optional space-separated trial budgets for sweep, e.g. 10 30 80 (overrides trials)"
        required: false
        default: ""
        type: string
      top_k:
        description: "Optional top-k override (empty uses scenario)"
        required: false
        default: ""
        type: string
      target_recall:
        description: "Optional recommendation threshold override (empty uses scenario)"
        required: false
        default: ""
        type: string
      max_queries:
        description: "Optional max_queries override (empty uses scenario)"
        required: false
        default: ""
        type: string
      compare_seeds:
        description: "Optional compare_seeds override (default: 5)"
        required: false
        default: "5"
        type: string

permissions:
  contents: read

jobs:
  tune:
    runs-on: ubuntu-latest
    timeout-minutes: 180
    env:
      INPUT_SCENARIO_NAME: ${{ github.event.inputs.scenario_name }}
      INPUT_DATASET_PATH: ${{ github.event.inputs.dataset_path }}
      INPUT_METRIC: ${{ github.event.inputs.metric }}
      INPUT_BACKENDS: ${{ github.event.inputs.backends }}
      INPUT_TRIALS: ${{ github.event.inputs.trials }}
      INPUT_TRIAL_BUDGETS: ${{ github.event.inputs.trial_budgets }}
      INPUT_TOP_K: ${{ github.event.inputs.top_k }}
      INPUT_TARGET_RECALL: ${{ github.event.inputs.target_recall }}
      INPUT_MAX_QUERIES: ${{ github.event.inputs.max_queries }}
      INPUT_COMPARE_SEEDS: ${{ github.event.inputs.compare_seeds }}
      OUTPUT_DIR: artifacts
      OUTPUT_JSON: artifacts/recommendations.json
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          lfs: false

      - name: Resolve scenario and dataset
        shell: bash
        run: |
          set -euo pipefail
          scenario_path="scenarios/${INPUT_SCENARIO_NAME}.yaml"
          if [[ ! -f "${scenario_path}" ]]; then
            echo "scenario file not found: ${scenario_path}" >&2
            exit 1
          fi

          resolved_dataset_path="${INPUT_DATASET_PATH}"
          if [[ -z "${resolved_dataset_path}" ]]; then
            resolved_dataset_path="$(
              awk '$1=="dataset:"{in_dataset=1; next} in_dataset&&/^[^[:space:]]/{in_dataset=0} in_dataset&&$1=="path:"{$1=""; sub(/^[[:space:]]+/, ""); gsub(/^["'"'"']|["'"'"']$/, ""); print; exit}' "${scenario_path}"
            )"
            if [[ -z "${resolved_dataset_path}" ]]; then
              echo "dataset.path not found in scenario: ${scenario_path}" >&2
              exit 1
            fi
          fi

          if [[ -z "${resolved_dataset_path}" ]]; then
            echo "dataset path is empty after scenario resolution" >&2
            exit 1
          fi
          if [[ "${resolved_dataset_path}" == /* ]]; then
            echo "dataset_path must be repository-relative, not absolute" >&2
            exit 1
          fi
          if [[ "${resolved_dataset_path}" == *".."* ]]; then
            echo "dataset_path must not include '..'" >&2
            exit 1
          fi
          if [[ ! -f "${resolved_dataset_path}" ]]; then
            echo "dataset_path not found in repository: ${resolved_dataset_path}" >&2
            exit 1
          fi
          attr="$(git check-attr filter -- "${resolved_dataset_path}" | awk '{print $3}')"
          if [[ "${attr}" != "lfs" ]]; then
            echo "dataset_path is not tracked by Git LFS: ${resolved_dataset_path}" >&2
            echo "Run: git lfs track \"datasets/**\" and recommit the dataset pointer file." >&2
            exit 1
          fi
          {
            echo "SCENARIO_PATH=${scenario_path}"
            echo "DATASET_PATH=${resolved_dataset_path}"
          } >> "${GITHUB_ENV}"

      - name: Fetch requested LFS object
        shell: bash
        run: |
          set -euo pipefail
          git lfs install --local
          git lfs pull --include "${DATASET_PATH}" --exclude ""
          ls -lh "${DATASET_PATH}"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install package
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -e ".[backends]"

      - name: Run tuning
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${OUTPUT_DIR}"

          backends_args=()
          if [[ -n "${INPUT_BACKENDS// }" ]]; then
            read -r -a backends_array <<< "${INPUT_BACKENDS}"
            if [[ ${#backends_array[@]} -gt 0 ]]; then
              backends_args=(--backends "${backends_array[@]}")
            fi
          fi
          metric_args=()
          if [[ -n "${INPUT_METRIC}" ]]; then
            metric_args=(--metric "${INPUT_METRIC}")
          fi
          top_k_args=()
          if [[ -n "${INPUT_TOP_K}" ]]; then
            top_k_args=(--top-k "${INPUT_TOP_K}")
          fi
          target_recall_args=()
          if [[ -n "${INPUT_TARGET_RECALL}" ]]; then
            target_recall_args=(--target-recall "${INPUT_TARGET_RECALL}")
          fi
          max_queries_args=()
          if [[ -n "${INPUT_MAX_QUERIES}" ]]; then
            max_queries_args=(--max-queries "${INPUT_MAX_QUERIES}")
          fi
          compare_seeds_args=()
          if [[ -n "${INPUT_COMPARE_SEEDS}" ]]; then
            compare_seeds_args=(--compare-seeds "${INPUT_COMPARE_SEEDS}")
          fi

          echo -e "trials\tbest_backend\tbest_recall\tbest_p95_ms" > "${OUTPUT_DIR}/budget_summary.tsv"

          run_one_budget() {
            local trial_budget="$1"
            local budget_dir="${OUTPUT_DIR}/budget_${trial_budget}"
            local output_json="${budget_dir}/recommendations.json"

            mkdir -p "${budget_dir}"

            trial_args=()
            if [[ -n "${trial_budget}" ]]; then
              trial_args=(--trials "${trial_budget}")
            fi

            python -m recallchemy \
              --scenario "${SCENARIO_PATH}" \
              --dataset "${DATASET_PATH}" \
              "${metric_args[@]}" \
              "${backends_args[@]}" \
              "${trial_args[@]}" \
              "${top_k_args[@]}" \
              "${target_recall_args[@]}" \
              "${max_queries_args[@]}" \
              "${compare_seeds_args[@]}" \
              --output "${output_json}"

            python -c 'import json, math, sys; from pathlib import Path; payload=json.loads(Path(sys.argv[1]).read_text(encoding="utf-8")); trials=sys.argv[2]; rows=payload.get("recommendations", []); target=float(payload.get("metadata", {}).get("target_recall", float("nan"))); rank=lambda rec: ((0.0, float(rec.get("metrics", {}).get("p95_query_ms", math.inf)), float(rec.get("metrics", {}).get("build_time_s", math.inf)), -float(rec.get("metrics", {}).get("recall", -math.inf))) if (math.isfinite(target) and float(rec.get("metrics", {}).get("recall", -math.inf)) >= target) else (1.0, -float(rec.get("metrics", {}).get("recall", -math.inf)), float(rec.get("metrics", {}).get("p95_query_ms", math.inf)), float(rec.get("metrics", {}).get("build_time_s", math.inf)))); best=min(rows, key=rank) if rows else None; trial_label=trials or str(payload.get("metadata", {}).get("trials_per_backend", "-")); print(f"{trial_label}\t-\t-\t-" if best is None else f"{trial_label}\t{best.get(\"backend\", \"-\")}\t{float(best.get(\"metrics\", {}).get(\"recall\", float(\"nan\"))):.4f}\t{float(best.get(\"metrics\", {}).get(\"p95_query_ms\", float(\"nan\"))):.4f}")' "${output_json}" "${trial_budget}" >> "${OUTPUT_DIR}/budget_summary.tsv"
          }

          budget_values=()
          if [[ -n "${INPUT_TRIAL_BUDGETS// }" ]]; then
            read -r -a budget_values <<< "${INPUT_TRIAL_BUDGETS}"
          elif [[ -n "${INPUT_TRIALS}" ]]; then
            budget_values=("${INPUT_TRIALS}")
          else
            # Empty string means: use scenario default trials.
            budget_values=("")
          fi

          for budget in "${budget_values[@]}"; do
            if [[ -n "${budget}" ]] && { ! [[ "${budget}" =~ ^[0-9]+$ ]] || [[ "${budget}" -le 0 ]]; }; then
              echo "invalid trial budget: ${budget}" >&2
              exit 1
            fi
            run_one_budget "${budget}"
          done

          first_budget="${budget_values[0]}"
          cp "${OUTPUT_DIR}/budget_${first_budget}/recommendations.json" "${OUTPUT_JSON}"
          cp "${OUTPUT_DIR}/budget_${first_budget}/recommendations.comparison.md" "${OUTPUT_DIR}/recommendations.comparison.md"
          cp "${OUTPUT_DIR}/budget_${first_budget}/recommendations.comparison.html" "${OUTPUT_DIR}/recommendations.comparison.html"

      - name: Summarize outputs
        shell: bash
        run: |
          set -euo pipefail
          {
            echo "## recallchemy report"
            echo ""
            echo "- scenario_name: \`${INPUT_SCENARIO_NAME}\`"
            echo "- scenario_path: \`${SCENARIO_PATH}\`"
            echo "- dataset_path: \`${DATASET_PATH}\`"
            echo "- primary_output_json: \`${OUTPUT_JSON}\`"
            echo "- primary_output_markdown: \`${OUTPUT_JSON%.json}.comparison.md\`"
            echo "- primary_output_html: \`${OUTPUT_JSON%.json}.comparison.html\`"
            echo ""
            echo "### trial budget summary"
            echo ""
            echo "| trials | best backend | best recall | best p95 ms | recall delta vs first | p95 reduction vs first |"
            echo "| ---: | --- | ---: | ---: | ---: | ---: |"
            awk -F'\t' '
              NR==1 { next }
              NR==2 {
                base_recall = ($3 == "-" ? 0/0 : $3 + 0)
                base_p95 = ($4 == "-" ? 0/0 : $4 + 0)
              }
              NR>=2 {
                recall_delta = "-"
                p95_reduction = "-"
                if ($3 != "-" && base_recall == base_recall) {
                  recall_delta = sprintf("%+.4f", ($3 + 0) - base_recall)
                }
                if ($4 != "-" && base_p95 == base_p95 && base_p95 > 0) {
                  p95_reduction = sprintf("%.1f%%", ((base_p95 - ($4 + 0)) / base_p95) * 100.0)
                }
                printf("| %s | %s | %s | %s | %s | %s |\n", $1, $2, $3, $4, recall_delta, p95_reduction)
              }
            ' "${OUTPUT_DIR}/budget_summary.tsv"
          } >> "${GITHUB_STEP_SUMMARY}"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: recallchemy-report-${{ github.run_id }}
          path: artifacts/**
