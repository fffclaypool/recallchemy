name: Tune From LFS Dataset

on:
  workflow_dispatch:
    inputs:
      dataset_path:
        description: "Repository-relative dataset path (Git LFS tracked), e.g. datasets/glove-100-angular.hdf5"
        required: true
        type: string
      metric:
        description: "Optional metric override (euclidean/angular/dot/cosine/l2/ip/inner_product)"
        required: false
        default: ""
        type: string
      backends:
        description: "Space-separated backends: all / hnswlib annoy faiss-ivf"
        required: false
        default: "all"
        type: string
      trials:
        description: "Optuna trials per backend"
        required: false
        default: "20"
        type: string
      trial_budgets:
        description: "Optional space-separated trial budgets for sweep, e.g. 10 30 80"
        required: false
        default: ""
        type: string
      top_k:
        description: "top-k for evaluation"
        required: false
        default: "10"
        type: string
      target_recall:
        description: "Recommendation threshold"
        required: false
        default: "0.95"
        type: string
      max_queries:
        description: "Cap query count to reduce runtime"
        required: false
        default: "500"
        type: string
      compare_seeds:
        description: "0 disables analysis; >0 enables multi-seed comparison"
        required: false
        default: "0"
        type: string

permissions:
  contents: read

jobs:
  tune:
    runs-on: ubuntu-latest
    timeout-minutes: 180
    env:
      DATASET_PATH: ${{ github.event.inputs.dataset_path }}
      INPUT_METRIC: ${{ github.event.inputs.metric }}
      INPUT_BACKENDS: ${{ github.event.inputs.backends }}
      INPUT_TRIALS: ${{ github.event.inputs.trials }}
      INPUT_TRIAL_BUDGETS: ${{ github.event.inputs.trial_budgets }}
      INPUT_TOP_K: ${{ github.event.inputs.top_k }}
      INPUT_TARGET_RECALL: ${{ github.event.inputs.target_recall }}
      INPUT_MAX_QUERIES: ${{ github.event.inputs.max_queries }}
      INPUT_COMPARE_SEEDS: ${{ github.event.inputs.compare_seeds }}
      OUTPUT_DIR: artifacts
      OUTPUT_JSON: artifacts/recommendations.json
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          lfs: false

      - name: Validate dataset input
        shell: bash
        run: |
          set -euo pipefail
          if [[ -z "${DATASET_PATH}" ]]; then
            echo "dataset_path is required" >&2
            exit 1
          fi
          if [[ "${DATASET_PATH}" == /* ]]; then
            echo "dataset_path must be repository-relative, not absolute" >&2
            exit 1
          fi
          if [[ "${DATASET_PATH}" == *".."* ]]; then
            echo "dataset_path must not include '..'" >&2
            exit 1
          fi
          if [[ ! -f "${DATASET_PATH}" ]]; then
            echo "dataset_path not found in repository: ${DATASET_PATH}" >&2
            exit 1
          fi
          attr="$(git check-attr filter -- "${DATASET_PATH}" | awk '{print $3}')"
          if [[ "${attr}" != "lfs" ]]; then
            echo "dataset_path is not tracked by Git LFS: ${DATASET_PATH}" >&2
            echo "Run: git lfs track \"datasets/**\" and recommit the dataset pointer file." >&2
            exit 1
          fi

      - name: Fetch requested LFS object
        shell: bash
        run: |
          set -euo pipefail
          git lfs install --local
          git lfs pull --include "${DATASET_PATH}" --exclude ""
          ls -lh "${DATASET_PATH}"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install package
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -e ".[backends]"

      - name: Run tuning
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${OUTPUT_DIR}"
          read -r -a backends_array <<< "${INPUT_BACKENDS}"
          if [[ ${#backends_array[@]} -eq 0 ]]; then
            backends_array=("all")
          fi
          metric_args=()
          if [[ -n "${INPUT_METRIC}" ]]; then
            metric_args=(--metric "${INPUT_METRIC}")
          fi

          echo -e "trials\tbest_backend\tbest_recall\tbest_p95_ms" > "${OUTPUT_DIR}/budget_summary.tsv"

          run_one_budget() {
            local trial_budget="$1"
            local budget_dir="${OUTPUT_DIR}/budget_${trial_budget}"
            local output_json="${budget_dir}/recommendations.json"

            mkdir -p "${budget_dir}"
            python -m recallchemy \
              --dataset "${DATASET_PATH}" \
              "${metric_args[@]}" \
              --backends "${backends_array[@]}" \
              --trials "${trial_budget}" \
              --top-k "${INPUT_TOP_K}" \
              --target-recall "${INPUT_TARGET_RECALL}" \
              --max-queries "${INPUT_MAX_QUERIES}" \
              --compare-seeds "${INPUT_COMPARE_SEEDS}" \
              --output "${output_json}"

            python - "${output_json}" "${trial_budget}" >> "${OUTPUT_DIR}/budget_summary.tsv" <<'PY'
import json
import math
import sys
from pathlib import Path

path = Path(sys.argv[1])
trials = sys.argv[2]
payload = json.loads(path.read_text(encoding="utf-8"))
rows = payload.get("recommendations", [])
if not rows:
    print(f"{trials}\t-\t-\t-")
    raise SystemExit(0)

def key_fn(rec):
    m = rec.get("metrics", {})
    return (-float(m.get("recall", -math.inf)), float(m.get("p95_query_ms", math.inf)))

best = sorted(rows, key=key_fn)[0]
metrics = best.get("metrics", {})
print(
    f"{trials}\t{best.get('backend', '-')}\t"
    f"{float(metrics.get('recall', float('nan'))):.4f}\t"
    f"{float(metrics.get('p95_query_ms', float('nan'))):.4f}"
)
PY
          }

          budget_values=()
          if [[ -n "${INPUT_TRIAL_BUDGETS// }" ]]; then
            read -r -a budget_values <<< "${INPUT_TRIAL_BUDGETS}"
          else
            budget_values=("${INPUT_TRIALS}")
          fi

          for budget in "${budget_values[@]}"; do
            if ! [[ "${budget}" =~ ^[0-9]+$ ]] || [[ "${budget}" -le 0 ]]; then
              echo "invalid trial budget: ${budget}" >&2
              exit 1
            fi
            run_one_budget "${budget}"
          done

          first_budget="${budget_values[0]}"
          cp "${OUTPUT_DIR}/budget_${first_budget}/recommendations.json" "${OUTPUT_JSON}"
          cp "${OUTPUT_DIR}/budget_${first_budget}/recommendations.comparison.md" "${OUTPUT_DIR}/recommendations.comparison.md"
          cp "${OUTPUT_DIR}/budget_${first_budget}/recommendations.comparison.html" "${OUTPUT_DIR}/recommendations.comparison.html"

      - name: Summarize outputs
        shell: bash
        run: |
          set -euo pipefail
          {
            echo "## recallchemy report"
            echo ""
            echo "- dataset_path: \`${DATASET_PATH}\`"
            echo "- primary_output_json: \`${OUTPUT_JSON}\`"
            echo "- primary_output_markdown: \`${OUTPUT_JSON%.json}.comparison.md\`"
            echo "- primary_output_html: \`${OUTPUT_JSON%.json}.comparison.html\`"
            echo ""
            echo "### trial budget summary"
            echo ""
            echo "| trials | best backend | best recall | best p95 ms |"
            echo "| ---: | --- | ---: | ---: |"
            tail -n +2 "${OUTPUT_DIR}/budget_summary.tsv" | while IFS=$'\t' read -r budget backend recall p95; do
              echo "| ${budget} | ${backend} | ${recall} | ${p95} |"
            done
          } >> "${GITHUB_STEP_SUMMARY}"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: recallchemy-report-${{ github.run_id }}
          path: artifacts/**
